---
title: "Philosophy of science"
editor_options: 
  chunk_output_type: console
---

## Provide a brief description of falsificationism and explain why Popper was motivated to develop this theory. Present one problem with the theory and assess whether the problem can be solved.

Falsificationism is a philosophy of science developed by Karl Popper. It is the idea that scientific theories may be falsified but never proven, meaning that the theory can be tested and likely disproven based on observations or experience [@Burke1986-by]. Popper meant that many scientific theories, such as psychoanalysis, simply explained every possible event and would therefore consider them unfalsifiable. He categorized such theories as pseudoscience referring to theories that claim to be scientific but lack the evidence or testability to be classified as genuine science [@Thornton2023-zq]. This view is what motivated Popper to develop his philosophy as falsification aimed to differentiate between pseudoscience and scientific theories.

Popper believed that a scientist should try to prove his own theory wrong, instead of looking for confirmation. He argued that induction is not possible and believed that it could not be rationally justified, hence, a confirmation would not be attainable as it requires induction. Furthermore, Popper argued that a good falsifiable theory should make precise and often multiple predictions [@Burke1986-by]. These predictions could identify ways in which the theory might be false and therefore reject it or aid in making some sense of further belief that the theory is possibly true. However, this may be challenging as rejecting a theory based on a single experiment provides a very vague way of determining where the fault lies. Something may have gone wrong without the fault of the theory itself as one of the auxiliary hypotheses used in that experiment could be at fault. In other words, if an experiment where to get an unexpected result, it does not necessarily mean that the theory is wrong but could mean that the experimental setup was flawed, or a wrong assumption was made. In conclusion, Popper’s way of testing and rejecting a theory makes it hard to know what exactly is being falsified, as testing a theory is not a straightforward process of disconfirmation and rejection.

A solution to the previously mentioned challenge that comes with the clean-cut falsification could be to adopt a more flexible approach. This way Popper’s philosophy may still be useful as we implement an approach that focuses more on the complexity of testing in real-world science while keeping the fundamental parts of his falsification philosophy. The new approach would adjust the auxiliary hypotheses while continuing to test the theory, meaning that the theory would not be rejected after a single experiment. In other words, a scientist would adjust their auxiliary hypothesis, continue to test their theory, and refine it based on new evidence. The original theory of Popper’s falsificationism is limited when it comes to acknowledging the complexity of actual scientific practice, but this new approach may diminish the problem.

In conclusion, Popper wanted to differentiate scientific theories from pseudoscience and argued that scientific theories cannot be confirmed but can only be tested and potentially disproven. This principle of clean falsification can be challenging when determining the source of unexpected results, a more flexible approach would therefore be more ideal to enhance the functionality of falsificationism in real-world scientific practice.

## Explain basic ideas of Bayesianism and how Bayesian probabilities can be interpreted. Present one problem with Bayesianism and evaluate how serious the problem is.

Bayesianism is an attempt to apply mathematical probability theory to understand the scientific process, including induction, falsification, and confirmation. Bayesians argue that all unknown quantities one wishes to draw conclusions about should be treated as random variables, and the uncertainty surrounding these quantities is described using a probability distribution [@Sober2002-zu]. Bayesianism is based on Bayes’ Theorem, which provides a way to update probabilities based on new evidence. The theorem is expressed as P(H\|E) = P(E\|H) \* P(H) / P(E) [@easwaran2011]. Easwaran further explains that the first variable of the formula, P(H\|E), is called posterior probability and is what we are trying to find. It states the probability of the hypothesis (H) given the evidence (E). To find the posterior probability we need to know the likelihood, P(E\|H), which is the probability of observing the evidence (E) given that the hypothesis (H) is true. In other words, how accurately the hypothesis can predict the evidence. We also need to know the prior probability, P(H), stating the probability of the hypothesis before the evidence is even considered. Lastly, P(E) is the marginal likelihood or the total probability of observing the evidence (E) under all hypotheses [@easwaran2011]. The more surprising the evidence (E), giving us a low probability, the higher the effect on the posterior probability of the hypothesis [@Vassend2024]. In simple term, Bayes’ Theorem allows us to incorporate prior knowledge and new evidence to produce a revised or updated probability.

Bayesian probabilities can be interpreted in several different ways. One way is where the probability is expressed as the researcher’s personal belief in the truth of a hypothesis. This interpretation is called personal belief where a researcher may say that there is a 99% probability that a theory is true, based on their individual conviction [@Vassend2024]. Secondly, there is collective belief where the probability represents the collective belief of most researchers. Here the percentage of probability would reflect a consensus among the majority of researchers in the field of study. Lastly, some Bayesians argue for a more objective type of probability suggesting that probability represents some universal truth, independent of individual researchers.

A central problem with Bayesianism is the determination of prior probabilities, or the subjectivity in the prior. This problem arises as different researchers may assign different priors based on their background knowledge, experience, or personal biases [@Sober2002-zu]. These priors will also lack objective evidentiary power, and researchers are more interested in objective data than in others subjective opinions [@easwaran2011]. As a result, the prior can skew the result, leading to misleading conclusions. Therefore, the problem with prior probabilities is serious as it undermines the objectivity of Bayesian analyses. Different prior probabilities can lead to radically different conclusions, even when using the same data. It is important to be aware of this issue, maintain transparency about the choice of prior probability, and focus on objective data [@Sober2002-zu].

In summary, Bayesianism provides a framework for incorporating uncertainty and prior knowledge when exploring scientific questions using probability. The approach is based on Bayes’ Theorem which facilitates the updating of probability based on new evidence. However, a significant issue lies in the determination of prior probabilities as they can introduce subjectivity and bias into analyses, resulting in misleading conclusions.
